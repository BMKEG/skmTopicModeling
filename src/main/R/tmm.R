# Reads topic model vectors from files like the ones 
# generated from a mallet model by the program
# edu.isi.bmkeg.skm.topicmodeling.bin.DumpTopicVectors
# Arguments: 
#    dtvFile: is a text file with one line per document
#        containing the topics proportions vector of that
#        document. Each line contains k real numbers separated by
#        tabs corresponding to the proportions of each one of the k
#        topics (from 1 to k).
#    idsFile: is a text file with one line per document 
#        containing the document's id. The order in which 
#        ids are listed in the file has to correspond to
#        the order in which the document' topics proportions 
#        vectors are listed in the file passed in the dtvFile argument. 

read.topicVectors <- function(idsFile, dtvFile) {
    # Reads dtvFile
	c <- scan(dtvFile)
	
	# Reads idsFile
	ids <- scan(idsFile)
	
	# computes number of topics
	n <- length(c) %/% length(ids)
	
	# Returns topics Vector matrix
	matrix(c, ncol = n, byrow=TRUE, 
		dimnames = list(documents=ids,topics=1:n))
}

# MAIN FUNCTION
# Arguments:
#   similarityGraphFile: a pairwise document similarity graphml file
#       as generated by edu.isi.bmkeg.skm.topicmodeling.bin.
#       ComputePairwiseDocumentSimilarities.
#   idsFile (see function read.topicVectors for a description of this argument)
#   dtvFile (see function read.topicVectors for a description of this argument)
#   edgecut: number between 0 and 1 to be passed as the edge.cut parameter
#       of the layout.drl function.
#   cntClusters: number of clusters to compute in the DrL layout
#   ... : other parameters to be passed to the plot() function
#
# Value:
#    a vector with the diagnostic topics per cluster
#
plotTMM.file <- function (similarityGraph, idsFile, dtvFile, edgecut = 0.8,
				cntClusters,sub=sprintf("edgecut: %.1f cntClusters: %g", edgecut, 
		cntClusters),...) {

	require("igraph")
	
	cat(date(), ': loading similarity graph from file ...\n')
	g <- read.graph(similarityGraph, format='graphml')

	cat(date(), ': loading topic vectors from files ...\n')
	tv <- read.topicVectors(idsFile, dtvFile)
	
	cat(date(), ': computing DrL layout from similarity graph ...\n')
	l <- layout.drl(g, options=list(edge.cut= edgecut))
	
	# Adding dimnames to layout
 	dimnames(l) <- list(documents=V(g)$name, coord=c('x','y'))
	
	plotTMM(l, tv, cntClusters, ... )

}

# Selects the top topic (i.e., the topic with highest proportion) of each topic vector
# Arguments:
#     tv: an array of topic vectors as a matrix.
#
# Value: a vector with the top topic of each topic vector in tv.
#
topTopics <- function(tv) {
	apply(tv,MARGIN=1, FUN=which.max)
}

# Selects the diagnostic topic of each topic vector
# Arguments:
#     ctv: an array of cluster topic vectors (one topic vector per cluster) as a matrix.
#     tv: the documents topic vectors
#
# Value: a vector with the diagnostoc topics of each topic vector in ctv.
#
diagTopics <- function(ctv, tv) {
	
	# Computes Mean Topic Vector across all documents topic vectors
	mtv <- meanTopicProp(tv)
	
	# Computes proportions ctv relative to mtv
	rctv <- t(ctv)/mtv
	 	
	apply(rctv,MARGIN=2, FUN=which.max)
}

diagTopicsWeights <- function(ctv, clt) {
	
	ctv[cbind(1:nrow(ctv),clt)]
}

diagTopicsRelWeights <- function(ctv,clt,tv) {
	
	# Computes Mean Topic Vector across all documents topic vectors
	mtv <- meanTopicProp(tv)

	# Computes proportions ctv relative to mtv
	rctv <- t(ctv)/mtv
	 	
	rctv[cbind(clt,1:nrow(ctv))]
}

# Computes distance between a node position in a layout to its cluster center
# Arguments:
#     l: nodes layout (as returned by the layout.drl() function)
#     cl: clusters over l computed using kmeans
# Value:
#     A vector with the euclidean distances
distToCenter <- function(l,cl) {
	euclidDist(l[,1],l[,2],cl$centers[cl$cluster,1],cl$centers[cl$cluster,2])
}

# Computes distance between the position of all nodes of a cluster to its center
# Arguments:
#     k: cluster number
#     l: nodes layout (as returned by the layout.drl() function)
#     cl: clusters over l computed using kmeans
# Value:
#     A vector with the euclidean distances
singleClusterDistToCenter <- function(k,l,cl) {
	i <- which(cl$cluster == k)
	euclidDist(l[i,1],l[i,2],cl$centers[k,1],cl$centers[k,2])
}


plotTMM <- function (l, tv, cntClusters, ... ) {
	
	cat(date(), ': computing clusters in the documents DrL layout ... \n')
	cl <- kmeans(l, centers = cntClusters, nstart = 10)
	
	cat(date(), ': computing mean topic vectors per cluster ...\n')
	clTv <- t(sapply(1:nrow(cl$centers), function(y,tv,cl) {colMeans(tv[which(cl$cluster == y),])},tv,cl))
	
	cat(date(), ': finding diagnostic topic per cluster ...\n')
	clt <- diagTopics(clTv,tv)
	
	cat(date(), ': ploting layout ...\n')
	plot(l, pch=20, cex=.1, col=cl$cluster,...)

	cat('printing labels ... \n')	
	text(x=cl$centers[,1],y=cl$centers[,2], labels = clt, pos=1, cex=1)
	
	cat(date(), ': End.')	
	
	return(cl)
}

# Computes mean proportions for each topic in the corpus
meanTopicProp <- function(tv) {
	colMeans(tv)
}

# Counts how many edges weighting more than a threshold a pairwise 
# document similarities graph would have.
# Arguments:
#    tv: document topic vectors matrix
#    threshold: similarity score cutoff threshold. Only
#       edges over this value will be included in the result.
#
# Value: a number
#
countEdges <- function(tv, threshold = 0.1) {
		
	cnt <- 0
    for (i in 1:(nrow(tv) - 1)) {
    	for (j in (i + 1):nrow(tv)) {
    		
    		c <- myCosine(tv[i,], tv[j,])
			
			if (c >= threshold) {
			
				cnt <- cnt + 1	
	
			}

    	}
    }
    
    total <- (nrow(tv) * (nrow(tv) -1)) / 2
    cat(sprintf("%d out of %d edges heavier than %f (%.2f percentile) \n",cnt,total,threshold, 1 - cnt/total))
	return(cnt)

 }	

# Computes pairwise document similarities
# Arguments:
#    tv: document topic vectors matrix
#    threshold: similarity score cutoff threshold. Only
#       edges over this value will be included in the result.
#
# Value: a weighted undirected igraph whose vertices correspond to
#       documents and whose edges weight are the similarity scores.
#
docSimilarities <- function(tv, threshold = 0.1, quadSize = 5000L) {
	
	require("igraph")

	cat(date(), ': Computing cosine distances \n')

	e <- findEdges(tv, quadSize = as.integer(quadSize), threshold = threshold)
	
	cat(date(), ': Constructing similarity graph \n')
	
	g <- graph.empty(directed=FALSE) + vertices(rownames(tv))

    g <- g + edges(as.vector(rbind(e$source,e$target)),weight=e$weight)
	
    cnt <- length(e$source)

    total <- (nrow(tv) * (nrow(tv) -1)) / 2
    cat(sprintf("%d out of %d edges included (%.2f percentile) \n",cnt,total, 1 - cnt/total))
    cat(sprintf("%d components \n",no.clusters(g)))

	cat(date(), '\n')

    return(g)
	
}

findEdges <- function(tv, quadSize = 5000L, threshold = 0.1) {
	quadSize <- as.integer(quadSize)
	re <- lapply(seq(from=1L,to=nrow(tv),by=quadSize), 
			FUN=function(i) {
				ce <- lapply(seq(from=1L, to=i, by=quadSize),
						FUN=function(j) {
							findQuadEdges(tv,sourceFrom=i, targetFrom=j, max=quadSize, threshold = threshold)
						})
				cat('Combining edges column ....')
				ces<-combineEdges(ce)
				cat('Done. \n')
				return(ces)
			})
	cat('Combining edges row ....')	
	res <- combineEdges(re)
	cat('Done. \n')
	return(res)
}

findQuadEdges <- function(tv, sourceFrom = 1L, targetFrom = 1L, max = 5000L, threshold = 0.1) {
	
	cat(sprintf("Computing Quadrant (sourceFrom, targetFrom, max): %d %d %d \n", sourceFrom, targetFrom,max))
	
	# Computes cosine distances of given tv rows
	tvcos <- myCosineM(tv, sourceFrom = sourceFrom, targetFrom = targetFrom, max = max)
	
	# Extracts indices and values for distances grater or equal than threshold
	thrIdx <- which(tvcos >= threshold)
	re <- row(tvcos)[thrIdx] + sourceFrom - 1L
	ce <- col(tvcos)[thrIdx] + targetFrom - 1L
	we <- tvcos[thrIdx]
	
	# Because edges are undirected we want only edges corresponding
	# to the upper triangle of the distance matrix
	lowerIndx <- which(re > ce)
	return(list(source=re[lowerIndx], target=ce[lowerIndx], weights=we[lowerIndx]))
}

myCosineM <- function(tv, sourceFrom = 1L, targetFrom = 1L, max = 5000) {
	
	sourceTo <- min(sourceFrom + max - 1, nrow(tv))
	targetTo <- min(targetFrom + max - 1, nrow(tv))
	
	# Computes cosine distances of given tv rows
	tvxy <- tcrossprod(tv[sourceFrom:sourceTo,], tv[targetFrom:targetTo,])
	tvxx <- sqrProd(tv[sourceFrom:sourceTo,])
	tvyy <- sqrProd(tv[targetFrom:targetTo,])
	tvxxm <- matrix(rep(x=tvxx,times=ncol(tvxy)),ncol=ncol(tvxy))
	tvyym <- matrix(rep(x=tvyy,times=nrow(tvxy)),nrow=nrow(tvxy), byrow=TRUE)
		
	return(tvxy / sqrt(tvxxm * tvyym))
}

combineEdges <- function(x) {
	source <- unlist(lapply(x,FUN=function(e){e$source}))
	target <- unlist(lapply(x,FUN=function(e){e$target}))
	weight <- unlist(lapply(x,FUN=function(e){e$weight}))
	
	return(list(source = source, target = target,weight=weight))
}

myCosine <- function(x,y) {
	return(x %*% y / sqrt(x%*%x * y%*%y))
}

# Given a matrix X(n,m) with Xi i=1..n vectors as rows,
# it computes a vector of crossprod(Xi,Xi) i=1..n
sqrProd <- function(x) {
 	return (rowSums(x*x))
}

write.layout <- function(l,g,file) {
	write.table(cbind(V(g)$name,l),file)
}

write.clusters <- function(c,g,clusterfile, centersfile) {
	write.table(cbind(V(g)$name,c$cluster),clusterfile)
	write.table(c$centers,centersfile)
}

euclidDist <- function(x1,y1,x2,y2) {
	sqrt((x1-x2)^2 + (y1-y2)^2)
}

#

